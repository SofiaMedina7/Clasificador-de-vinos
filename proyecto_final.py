# -*- coding: utf-8 -*-
"""Proyecto Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lZnMeyS6C1Eo5ymjCc3qF1yUejh3F4Yl
"""

import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt

from os import X_OK
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn import decomposition
from sklearn.decomposition import PCA, KernelPCA

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import PolynomialFeatures

from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

df=pd.read_csv("redwinequality.csv", sep=',',header=0)
arr=df.values
Xo=arr[:,1:12]
Y=arr[:,13]
y=np.transpose(Y)

scaler = StandardScaler()
scaler.fit(Xo)
X = scaler.transform(Xo)

print(y)

"""## PCA"""

n=9
pca = decomposition.PCA(n_components=n,whiten=True)

pca.fit(X)
X_pca = pca.transform(X)

print("Pesos de PCA:",pca.explained_variance_ratio_)

X_train, X_test, y_train, y_test = train_test_split(X_pca, y,test_size=0.25, random_state=0)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

print(y_train.shape)

"""# Support vector machine"""

kernels=['linear', 'poly', 'poly', 'rbf', 'sigmoid']

a_svm = []
f1_svm = []
mcc_svm = []


for s in range(0,4):
  if s == 0: #lineal
    g = 0.01
    d = 3
    c = 0
  if s == 1: #cubica
    g = 'scale'
    d = 3
    c = 0
  if s == 2: #cuadratica
    g = 'scale'
    d = 4
    c = 1
  if s == 3: #cuadratica
    g = (1/2)*15
    d = 3
    c = 0
  if s == 3: #sigmoid
    g = 'auto'
    d = 3
    c = 0

  Kernel=s
  msv = svm.SVC(kernel=kernels[Kernel],gamma=g,degree=d,coef0=c)
  msv.fit(X_train, y_train)
    
  y_test_predicted_svm = msv.predict(X_test)

  acc = accuracy_score(y_test, y_test_predicted_svm)
  a_svm.append(acc)
  f1 = f1_score(y_test, y_test_predicted_svm,average='micro')
  f1_svm.append(f1)
  mcc = matthews_corrcoef(y_test, y_test_predicted_svm)
  mcc_svm.append(mcc)

  print(classification_report(y_test, y_test_predicted_svm))


print(a_svm)
print(f1_svm)
print(mcc_svm)

"""# Naive Bayes"""

Gau = GaussianNB()
Gau.fit(X_train, y_train)

y_test_predicted_NB = Gau.predict(X_test)

acc = accuracy_score(y_test, y_test_predicted_NB)
f1 = f1_score(y_test, y_test_predicted_NB,average='micro')
mcc = matthews_corrcoef(y_test, y_test_predicted_NB)

print(acc)
print(f1)
print(mcc)
print(classification_report(y_test, y_test_predicted_NB))

"""# Redes neuronales"""

activations = ['identity', 'logistic', 'tanh', 'relu']

a_mlp = []
f1_mlp = []
mcc_mlp = []

for p in [0,1,2,3]:
  for j in range(10,60,10):
      mlp = MLPClassifier(hidden_layer_sizes=(j*2,j,j*2),alpha=0.01,activation=activations[p],random_state=1,learning_rate='adaptive', max_iter=1000,solver="adam",verbose=False)
      mlp.fit(X_train, y_train)

      y_test_predicted_mlp = mlp.predict(X_test)

      acc = accuracy_score(y_test, y_test_predicted_mlp)
      a_mlp.append(acc)
      f1 = f1_score(y_test, y_test_predicted_mlp,average='micro')
      f1_mlp.append(f1)
      mcc = matthews_corrcoef(y_test, y_test_predicted_mlp)
      mcc_mlp.append(mcc)

      print('metodo de activacion:',activations[p])
      print('Tamano de capas:',j)
      print(classification_report(y_test, y_test_predicted_svm))
  

print(a_mlp)
print(f1_mlp)
print(mcc_mlp)

"""# KNN"""

weight = ['uniform', 'distance']

a_knn = []
f1_knn = []
mcc_knn = []


for g in [0,1]:
  for m in range(1,10):
    n_neighbors = m
 
    knn = KNeighborsClassifier(n_neighbors)
    knn.fit(X_train, y_train)
 
    y_test_predicted_knn = knn.predict(X_test)

    acc = accuracy_score(y_test, y_test_predicted_knn)
    a_knn.append(acc)
    f1 = f1_score(y_test, y_test_predicted_knn,average='micro')
    f1_knn.append(f1)
    mcc = matthews_corrcoef(y_test, y_test_predicted_knn)
    mcc_knn.append(mcc)

    print('Vecinos:',m)
    print(classification_report(y_test, y_test_predicted_knn))


print(a_knn)
print(f1_knn)
print(mcc_knn)

"""#Modelo Entregable"""

activations = ['identity', 'logistic', 'tanh', 'relu']

p = 3
Modelo = MLPClassifier(hidden_layer_sizes=(60,30,60),alpha=0.01,activation=activations[p],random_state=1,learning_rate='adaptive', max_iter=1000,solver="adam",verbose=False)
Modelo.fit(X, y)